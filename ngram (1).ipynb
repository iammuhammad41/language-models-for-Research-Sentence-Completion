{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ngram.ipynb","provenance":[{"file_id":"1tWSfhmTUjo4TNeuZ5GDLaSs7O4mZEoiw","timestamp":1659624651176}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"s_EWWH2yRewt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660234465838,"user_tz":-480,"elapsed":41173,"user":{"displayName":"Muhammad Altaf","userId":"03105077489695775624"}},"outputId":"c19d8677-4fe2-49bd-d3e3-00d2f9f04b21"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["\n","# from google.colab import drive\n","# drive.mount('/content/drive')\n","\n","import pandas as pd\n","import os\n","mrscc_dir = '/content/drive/MyDrive/ColabNotebooks/lab2resources/sentence-completion'\n","questions = pd.read_csv(os.path.join(mrscc_dir,\"testing_data.csv\"))\n","answers = pd.read_csv(os.path.join(mrscc_dir,\"test_answer.csv\"))\n","\n","import os,random,math,sys\n","import pandas as pd\n","import numpy as np\n","import nltk\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from nltk.tokenize import sent_tokenize\n","from nltk.tokenize import word_tokenize\n","from nltk import ne_chunk,ne_chunk_sents,pos_tag,tree2conlltags\n","from nltk.corpus import words\n","import spacy\n","from spacy.lang.en import English\n","from spacy.tokenizer import Tokenizer\n","from tqdm import tqdm\n","nltk.download('words')\n","vocab=words.words()\n","nltk.download('punkt')\n","nltk.download('maxent_ne_chunker')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('words')\n","spacy_nlp = spacy.load(\"en_core_web_sm\")\n","\n","import csv\n","import sys, os\n","sys.path.append(os.getcwd()) # may need to change this\n","# from simple_classical_approach import *\n","\n","class question(question):\n","    def get_tokens(self):\n","        return [\"__START\"]+tokenize(self.fields[question.colnames[\"question\"]])+[\"__END\"]\n","    \n","    def get_left_context(self,window=1,target=\"_____\"):\n","        found=-1\n","        sent_tokens=self.get_tokens()\n","        for i,token in enumerate(sent_tokens):\n","            if token==target:\n","                found=i\n","                break  \n","            \n","        if found>-1:\n","            return sent_tokens[i-window:i]\n","        else:\n","            return []\n","\n","    def choose(self,lm,method=\"bigram\",choices=[]):\n","        if choices==[]:\n","            choices=[\"a\",\"b\",\"c\",\"d\",\"e\"]\n","        if method==\"bigram\":\n","            rc=self.get_right_context(window=1)\n","            lc=self.get_left_context(window=1)\n","            probs=[lm.get_prob(rc[0],[self.get_field(ch+\")\")],methodparams={\"method\":method.split(\"_\")[0]})*lm.get_prob(self.get_field(ch+\")\"),lc,methodparams={\"method\":method.split(\"_\")[0]}) for ch in choices]\n","        elif method==\"bigram_right\":\n","            context=self.get_right_context(window=1)\n","            probs=[lm.get_prob(context[0],[self.get_field(ch+\")\")],methodparams={\"method\":method.split(\"_\")[0]}) for ch in choices]\n","        else:\n","            context=self.get_left_context(window=1)\n","            probs=[lm.get_prob(self.get_field(ch+\")\"),context,methodparams={\"method\":method.split(\"_\")[0]}) for ch in choices]\n","        maxprob=max(probs)\n","        bestchoices=[ch for ch,prob in zip(choices,probs) if prob == maxprob]\n","        #if len(bestchoices)>1:\n","        #    print(\"Randomly choosing from {}\".format(len(bestchoices)))\n","        return np.random.choice(bestchoices)\n","    \n","    def choose_backoff(self,lm,methods=['bigram','unigram'],choices=[\"a\",\"b\",\"c\",\"d\",\"e\"]):\n","        context=self.get_left_context(window=1)\n","        probs=[lm.get_prob(self.get_field(ch+\")\"),context,methodparams={\"method\":methods[0]}) for ch in choices]\n","        maxprob=max(probs)\n","        bestchoices=[ch for ch,prob in zip(choices,probs) if prob == maxprob]\n","        if len(bestchoices)>1:\n","            print(\"Backing off on {}\".format(len(bestchoices)))\n","        return self.choose(lm,choices=bestchoices,method=methods[1])\n","    \n","    def predict(self,method=\"chooseA\",model=mylm):\n","        if method==\"chooseA\":\n","            return self.chooseA()\n","        elif method==\"random\":\n","            return self.chooserandom()\n","        elif method==\"bigram_backoff\":\n","            return self.choose_backoff(mylm,methods=[\"bigram\",\"unigram\"])\n","        else:\n","            return self.choose(mylm,method=method)\n","    \n","class scc_reader:\n","    \n","    def __init__(self,qs=questions,ans=answers):\n","        self.qs=qs\n","        self.ans=ans\n","        self.read_files()\n","        \n","    def read_files(self):\n","        \n","        #read in the question file\n","        with open(self.qs) as instream:\n","            csvreader=csv.reader(instream)\n","            qlines=list(csvreader)\n","        \n","        #store the column names as a reverse index so they can be used to reference parts of the question\n","        question.colnames={item:i for i,item in enumerate(qlines[0])}\n","        \n","        #create a question instance for each line of the file (other than heading line)\n","        self.questions=[question(qline) for qline in qlines[1:]]\n","        \n","        #read in the answer file\n","        with open(self.ans) as instream:\n","            csvreader=csv.reader(instream)\n","            alines=list(csvreader)\n","            \n","        #add answers to questions so predictions can be checked    \n","        for q,aline in zip(self.questions,alines[1:]):\n","            q.add_answer(aline)\n","        \n","    def get_field(self,field):\n","        return [q.get_field(field) for q in self.questions] \n","    \n","    def predict(self,method=\"chooseA\"):\n","        return [q.predict(method=method) for q in self.questions]\n","    \n","    def predict_and_score(self,method=\"chooseA\"):\n","        scores=[q.predict_and_score(method=method) for q in self.questions]\n","        return sum(scores)/len(scores)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":443},"id":"kD1OMo8nV8Cj","executionInfo":{"status":"error","timestamp":1660234508781,"user_tz":-480,"elapsed":11704,"user":{"displayName":"Muhammad Altaf","userId":"03105077489695775624"}},"outputId":"f6735b10-52b9-4a0a-a24f-bca20dc53997"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package words to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/words.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package maxent_ne_chunker to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data] Downloading package words to /root/nltk_data...\n","[nltk_data]   Package words is already up-to-date!\n"]},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-ac8ae914d610>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# from simple_classical_approach import *\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"__START\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"question\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"__END\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'question' is not defined"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"b_UTvy6XoB8d"},"execution_count":null,"outputs":[]}]}